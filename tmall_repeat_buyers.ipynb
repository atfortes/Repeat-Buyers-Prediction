{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Big Data Intelligence Project - TMALL Repeat Buyers**\n",
    "### **Armando Fortes, David Pissarra, Gabriele Oliaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from xgboost import train\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_1 = '../data_format1/'\n",
    "DATA_DIR_2 = '../data_format2/'\n",
    "TRAIN_PATH = DATA_DIR_1 + 'train_format1.csv'\n",
    "TEST_PATH = DATA_DIR_1 + 'test_format1.csv'\n",
    "USER_INFO_PATH = DATA_DIR_1 + 'user_info_format1.csv'\n",
    "USER_LOG_PATH = DATA_DIR_1 + 'user_log_format1.csv'\n",
    "DOUBLE11_DAY = 184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SET_SIZE = 0.2\n",
    "PCA_COMPONENTS = 5\n",
    "RANDOM_SEED = 42\n",
    "N_FEATURES = 150\n",
    "EPSILON = 1e-10\n",
    "SPLITS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_user_info = pd.read_csv(USER_INFO_PATH)\n",
    "df_user_log = pd.read_csv(USER_LOG_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)\n",
    "df_test.drop('prob', axis=1, inplace=True)\n",
    "\n",
    "df_train['kind'] = 'train'\n",
    "df_test['kind'] = 'test'\n",
    "df = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize memory usage and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{round(df_user_log.memory_usage().sum() / 2**30, 2)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_log['user_id'] = df_user_log['user_id'].astype(np.int32)\n",
    "df_user_log['item_id'] = df_user_log['item_id'].astype(np.int32)\n",
    "df_user_log['cat_id'] = df_user_log['cat_id'].astype(np.int16)\n",
    "df_user_log['seller_id'] = df_user_log['seller_id'].astype(np.int16)\n",
    "df_user_log.rename(columns={'seller_id' : 'merchant_id'}, inplace=True)\n",
    "df_user_log['brand_id'].fillna(0, inplace=True)\n",
    "df_user_log['brand_id'] = df_user_log['brand_id'].astype(np.int16)\n",
    "df_user_log['time_stamp'] = (pd.to_datetime(df_user_log['time_stamp'], format='%m%d') - pd.to_datetime(df_user_log['time_stamp'].min(), format='%m%d')).dt.days\n",
    "df_user_log['time_stamp'] = df_user_log['time_stamp'].astype(np.int16)\n",
    "df_user_log['action_type'] = df_user_log['action_type'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{round(df_user_log.memory_usage().sum() / 2**30, 2)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_log['time_stamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_info['age_range'].fillna(0, inplace=True)\n",
    "df_user_info['gender'].fillna(2, inplace=True)\n",
    "df_user_info['age_range'] = df_user_info['age_range'].astype(np.int8)\n",
    "df_user_info['gender'] = df_user_info['gender'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_user_log.groupby('user_id')\n",
    "merchants = df_user_log.groupby('merchant_id')\n",
    "users_merchants = df_user_log.groupby(['user_id', 'merchant_id'])\n",
    "df_user_log['time_period'] = df_user_log['time_stamp'] // 31\n",
    "\n",
    "double11 = (df_user_log[df_user_log['time_stamp'] == DOUBLE11_DAY]).reset_index(drop=True)\n",
    "double11_users = double11.groupby('user_id')\n",
    "double11_merchants = double11.groupby('merchant_id')\n",
    "double11_users_merchants = double11.groupby(['user_id', 'merchant_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General counting and ratio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform age categorical features into different binary features\n",
    "to_merge = pd.get_dummies(df_user_info, prefix='age', columns=['age_range'])\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given user \n",
    "to_merge = users.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user', \n",
    "    'cat_id': 'categories_user',\n",
    "    'merchant_id': 'merchants_user',\n",
    "    'brand_id': 'brands_user',\n",
    "    'time_stamp': 'dates_user',\n",
    "    'time_period': 'periods_user',\n",
    "    'action_type': 'action_types_user'\n",
    "    })\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given merchant \n",
    "to_merge = merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_merchant', \n",
    "    'cat_id': 'categories_merchant',\n",
    "    'user_id': 'users_merchant',\n",
    "    'brand_id': 'brands_merchant',\n",
    "    'time_stamp': 'dates_merchant',\n",
    "    'time_period': 'periods_merchant',\n",
    "    'action_type': 'action_types_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given user and merchant\n",
    "to_merge = users_merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user_merchant', \n",
    "    'cat_id': 'categories_user_merchant',\n",
    "    'brand_id': 'brands_user_merchant',\n",
    "    'time_stamp': 'dates_user_merchant',\n",
    "    'time_period': 'periods_user_merchant',\n",
    "    'action_type': 'action_types_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# count total actions by type for a given user\n",
    "to_merge = users['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_user',\n",
    "    1: 'carts_user',\n",
    "    2: 'purchases_user',\n",
    "    3: 'favourites_user'\n",
    "    })\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total actions by type for a given merchant\n",
    "to_merge = merchants['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_merchant', \n",
    "    1: 'carts_merchant',\n",
    "    2: 'purchases_merchant',\n",
    "    3: 'favourites_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total actions by type for a given pair (user, merchant)\n",
    "to_merge = users_merchants['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_user_merchant',\n",
    "    1: 'carts_user_merchant',\n",
    "    2: 'purchases_user_merchant',\n",
    "    3: 'favourites_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# ratio of actions in each merchant (user perspective)\n",
    "df['clicks_in_merchant_ratio_perspective'] = df['clicks_user_merchant'] / (df['clicks_user'] + EPSILON)\n",
    "df['carts_in_merchant_ratio_perspective'] = df['carts_user_merchant'] / (df['carts_user'] + EPSILON)\n",
    "df['purchases_in_merchant_ratio_perspective'] = df['purchases_user_merchant'] / (df['purchases_user'] + EPSILON)\n",
    "df['favourites_in_merchant_ratio_perspective'] = df['favourites_user_merchant'] / (df['favourites_user'] + EPSILON)\n",
    "\n",
    "# ratio of actions in each merchant (merchant perspective)\n",
    "df['clicks_by_user_ratio_perspective'] = df['clicks_user_merchant'] / (df['clicks_merchant'] + EPSILON)\n",
    "df['carts_by_user_ratio_perspective'] = df['carts_user_merchant'] / (df['carts_merchant'] + EPSILON)\n",
    "df['purchases_by_user_ratio_perspective'] = df['purchases_user_merchant'] / (df['purchases_merchant'] + EPSILON)\n",
    "df['favourites_by_user_ratio_perspective'] = df['favourites_user_merchant'] / (df['favourites_merchant'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given user\n",
    "df['clicks_user_ratio'] = df['clicks_user'] / (df['clicks_user'] + df['carts_user'] + df['purchases_user'] + df['favourites_user'] + EPSILON)\n",
    "df['carts_user_ratio'] = df['carts_user'] / (df['clicks_user'] + df['carts_user'] + df['purchases_user'] + df['favourites_user'] + EPSILON)\n",
    "df['purchases_user_ratio'] = df['purchases_user'] / (df['clicks_user'] + df['carts_user'] + df['purchases_user'] + df['favourites_user'] + EPSILON)\n",
    "df['favourites_user_ratio'] = df['favourites_user'] / (df['clicks_user'] + df['carts_user'] + df['purchases_user'] + df['favourites_user'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given merchant\n",
    "df['clicks_merchant_ratio'] = df['clicks_merchant'] / (df['clicks_merchant'] + df['carts_merchant'] + df['purchases_merchant'] + df['favourites_merchant'] + EPSILON)\n",
    "df['carts_merchant_ratio'] = df['carts_merchant'] / (df['clicks_merchant'] + df['carts_merchant'] + df['purchases_merchant'] + df['favourites_merchant'] + EPSILON)\n",
    "df['purchases_merchant_ratio'] = df['purchases_merchant'] / (df['clicks_merchant'] + df['carts_merchant'] + df['purchases_merchant'] + df['favourites_merchant'] + EPSILON)\n",
    "df['favourites_merchant_ratio'] = df['favourites_merchant'] / (df['clicks_merchant'] + df['carts_merchant'] + df['purchases_merchant'] + df['favourites_merchant'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given pair (user, merchant)\n",
    "df['clicks_user_merchant_ratio'] = df['clicks_user_merchant'] / (df['clicks_user_merchant'] + df['carts_user_merchant'] + df['purchases_user_merchant'] + df['favourites_user_merchant'] + EPSILON)\n",
    "df['carts_user_merchant_ratio'] = df['carts_user_merchant'] / (df['clicks_user_merchant'] + df['carts_user_merchant'] + df['purchases_user_merchant'] + df['favourites_user_merchant'] + EPSILON)\n",
    "df['purchases_user_merchant_ratio'] = df['purchases_user_merchant'] / (df['clicks_user_merchant'] + df['carts_user_merchant'] + df['purchases_user_merchant'] + df['favourites_user_merchant'] + EPSILON)\n",
    "df['favourites_user_merchant_ratio'] = df['favourites_user_merchant'] / (df['clicks_user_merchant'] + df['carts_user_merchant'] + df['purchases_user_merchant'] + df['favourites_user_merchant'] + EPSILON)\n",
    "\n",
    "# interval features\n",
    "to_merge = (users['time_stamp'].max() - users['time_stamp'].min()).rename('interval')\n",
    "df = df.merge(to_merge, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendline(x, y):\n",
    "    n = x.shape[1]\n",
    "    sum_x = np.sum(x)\n",
    "    sum_x_2 = np.sum(x**2)\n",
    "    sum_y = np.sum(y, axis=1)\n",
    "    u = (n * np.dot(y, x.T)) - (sum_x * sum_y).reshape(-1, 1)\n",
    "    l = np.sum(sum_x_2) - (sum_x ** 2)\n",
    "    return (u / l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_time = df_user_log.groupby(['user_id', 'time_period'])\n",
    "\n",
    "to_merge = users_time['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_user',\n",
    "    1: 'carts_user',\n",
    "    2: 'purchases_user',\n",
    "    3: 'favourites_user'\n",
    "    }).reset_index()\n",
    "\n",
    "to_merge_aux = to_merge.groupby('user_id').max().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_user': 'clicks_user_period_max',\n",
    "    'carts_user': 'carts_user_period_max',\n",
    "    'purchases_user': 'purchases_user_period_max',\n",
    "    'favourites_user': 'favourites_user_period_max'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='user_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('user_id').mean().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_user': 'clicks_user_period_mean',\n",
    "    'carts_user': 'carts_user_period_mean',\n",
    "    'purchases_user': 'purchases_user_period_mean',\n",
    "    'favourites_user': 'favourites_user_period_mean'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='user_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('user_id').std().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_user': 'clicks_user_period_std',\n",
    "    'carts_user': 'carts_user_period_std',\n",
    "    'purchases_user': 'purchases_user_period_std',\n",
    "    'favourites_user': 'favourites_user_period_std'\n",
    "}).fillna(0)\n",
    "df = df.merge(to_merge_aux, on='user_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('user_id').median().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_user': 'clicks_user_period_median',\n",
    "    'carts_user': 'carts_user_period_median',\n",
    "    'purchases_user': 'purchases_user_period_median',\n",
    "    'favourites_user': 'favourites_user_period_median'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='user_id', how='left')\n",
    "\n",
    "to_merge = to_merge.groupby(['user_id', 'time_period']).sum().unstack().fillna(0).stack().reset_index()\n",
    "to_merge = to_merge.pivot_table(values=['clicks_user', 'carts_user', 'purchases_user', 'favourites_user'], index='user_id', columns='time_period')\n",
    "to_merge.columns = ['_period_'.join(str(x) for x in col) for col in to_merge.columns.values]\n",
    "df = df.merge(to_merge, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users trendline\n",
    "purchase_col = [col for col in df if col.startswith('purchases_user_period') and col[-1].isdigit()]\n",
    "x = np.array([int(col[-1]) for col in purchase_col]).reshape(1, -1)\n",
    "y = df[purchase_col].to_numpy()\n",
    "df['purchase_user_trendline'] = trendline(x, y)\n",
    "\n",
    "clicks_col = [col for col in df if col.startswith('clicks_user_period') and col[-1].isdigit()]\n",
    "y = df[clicks_col].to_numpy()\n",
    "df['clicks_user_trendline'] = trendline(x, y)\n",
    "\n",
    "carts_col = [col for col in df if col.startswith('carts_user_period') and col[-1].isdigit()]\n",
    "y = df[carts_col].to_numpy()\n",
    "df['carts_user_trendline'] = trendline(x, y)\n",
    "\n",
    "favourites_col = [col for col in df if col.startswith('favourites_user_period') and col[-1].isdigit()]\n",
    "y = df[favourites_col].to_numpy()\n",
    "df['favourites_user_trendline'] = trendline(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants_time = df_user_log.groupby(['merchant_id', 'time_period'])\n",
    "\n",
    "to_merge = merchants_time['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_merchant',\n",
    "    1: 'carts_merchant',\n",
    "    2: 'purchases_merchant',\n",
    "    3: 'favourites_merchant'\n",
    "    }).reset_index()\n",
    "\n",
    "to_merge_aux = to_merge.groupby('merchant_id').max().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_merchant': 'clicks_merchant_period_max',\n",
    "    'carts_merchant': 'carts_merchant_period_max',\n",
    "    'purchases_merchant': 'purchases_merchant_period_max',\n",
    "    'favourites_merchant': 'favourites_merchant_period_max'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='merchant_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('merchant_id').mean().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_merchant': 'clicks_merchant_period_mean',\n",
    "    'carts_merchant': 'carts_merchant_period_mean',\n",
    "    'purchases_merchant': 'purchases_merchant_period_mean',\n",
    "    'favourites_merchant': 'favourites_merchant_period_mean'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='merchant_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('merchant_id').std().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_merchant': 'clicks_merchant_period_std',\n",
    "    'carts_merchant': 'carts_merchant_period_std',\n",
    "    'purchases_merchant': 'purchases_merchant_period_std',\n",
    "    'favourites_merchant': 'favourites_merchant_period_std'\n",
    "}).fillna(0)\n",
    "df = df.merge(to_merge_aux, on='merchant_id', how='left')\n",
    "to_merge_aux = to_merge.groupby('merchant_id').median().drop('time_period', axis=1).rename(columns={\n",
    "    'clicks_merchant': 'clicks_merchant_period_median',\n",
    "    'carts_merchant': 'carts_merchant_period_median',\n",
    "    'purchases_merchant': 'purchases_merchant_period_median',\n",
    "    'favourites_merchant': 'favourites_merchant_period_median'\n",
    "})\n",
    "df = df.merge(to_merge_aux, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = to_merge.groupby(['merchant_id', 'time_period']).sum().unstack().fillna(0).stack().reset_index()\n",
    "to_merge = to_merge.pivot_table(values=['clicks_merchant', 'carts_merchant', 'purchases_merchant', 'favourites_merchant'], index='merchant_id', columns='time_period')\n",
    "to_merge.columns = ['_period_'.join(str(x) for x in col) for col in to_merge.columns.values]\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merchants trendline\n",
    "purchase_col = [col for col in df if col.startswith('purchases_merchant_period') and col[-1].isdigit()]\n",
    "x = np.array([int(col[-1]) for col in purchase_col]).reshape(1, -1)\n",
    "y = df[purchase_col].to_numpy()\n",
    "df['purchase_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "clicks_col = [col for col in df if col.startswith('clicks_merchant_period') and col[-1].isdigit()]\n",
    "y = df[clicks_col].to_numpy()\n",
    "df['clicks_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "carts_col = [col for col in df if col.startswith('carts_merchant_period') and col[-1].isdigit()]\n",
    "y = df[carts_col].to_numpy()\n",
    "df['carts_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "favourites_col = [col for col in df if col.startswith('favourites_merchant_period') and col[-1].isdigit()]\n",
    "y = df[favourites_col].to_numpy()\n",
    "df['favourites_merchant_trendline'] = trendline(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users-Merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_merchants_time = df_user_log.groupby(['user_id', 'merchant_id', 'time_period'])\n",
    "\n",
    "to_merge = users_merchants_time['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'clicks_user_merchant',\n",
    "    1: 'carts_user_merchant',\n",
    "    2: 'purchases_user_merchant',\n",
    "    3: 'favourites_user_merchant'\n",
    "    }).reset_index()\n",
    "to_merge = to_merge.groupby(['user_id', 'merchant_id', 'time_period']).sum().unstack().fillna(0).stack().reset_index()\n",
    "to_merge = to_merge.pivot_table(values=['clicks_user_merchant', 'carts_user_merchant', 'purchases_user_merchant', 'favourites_user_merchant'], index=['user_id', 'merchant_id'], columns='time_period')\n",
    "to_merge.columns = ['_period_'.join(str(x) for x in col) for col in to_merge.columns.values]\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-merchants trendline\n",
    "purchase_col = [col for col in df if col.startswith('purchases_user_merchant_period') and col[-1].isdigit()]\n",
    "x = np.array([int(col[-1]) for col in purchase_col]).reshape(1, -1)\n",
    "y = df[purchase_col].to_numpy()\n",
    "df['purchase_user_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "clicks_col = [col for col in df if col.startswith('clicks_user_merchant_period') and col[-1].isdigit()]\n",
    "y = df[clicks_col].to_numpy()\n",
    "df['clicks_user_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "carts_col = [col for col in df if col.startswith('carts_user_merchant_period') and col[-1].isdigit()]\n",
    "y = df[carts_col].to_numpy()\n",
    "df['carts_user_merchant_trendline'] = trendline(x, y)\n",
    "\n",
    "favourites_col = [col for col in df if col.startswith('favourites_user_merchant_period') and col[-1].isdigit()]\n",
    "y = df[favourites_col].to_numpy()\n",
    "df['favourites_user_merchant_trendline'] = trendline(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double11 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of unique values from each feature for a given user \n",
    "to_merge = double11_users.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double11_items_user', \n",
    "    'cat_id': 'double11_categories_user',\n",
    "    'merchant_id': 'double11_merchants_user',\n",
    "    'brand_id': 'double11_brands_user',\n",
    "    'time_stamp': 'double11_dates_user',\n",
    "    'time_period': 'double11_periods_user',\n",
    "    'action_type': 'double11_action_types_user'\n",
    "    })\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given merchant \n",
    "to_merge = double11_merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double11_items_merchant', \n",
    "    'cat_id': 'double11_categories_merchant',\n",
    "    'user_id': 'double11_users_merchant',\n",
    "    'brand_id': 'double11_brands_merchant',\n",
    "    'time_stamp': 'double11_dates_merchant',\n",
    "    'time_period': 'double11_periods_merchant',\n",
    "    'action_type': 'double11_action_types_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given user and merchant\n",
    "to_merge = double11_users_merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double11_items_user_merchant', \n",
    "    'cat_id': 'double11_categories_user_merchant',\n",
    "    'brand_id': 'double11_brands_user_merchant',\n",
    "    'time_stamp': 'double11_dates_user_merchant',\n",
    "    'time_period': 'double11_periods_user_merchant',\n",
    "    'action_type': 'double11_action_types_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# count total actions by type for a given user\n",
    "to_merge = double11_users['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double11_clicks_user',\n",
    "    1: 'double11_carts_user',\n",
    "    2: 'double11_purchases_user',\n",
    "    3: 'double11_favourites_user'\n",
    "    })\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total actions by type for a given merchant\n",
    "to_merge = double11_merchants['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double11_clicks_merchant', \n",
    "    1: 'double11_carts_merchant',\n",
    "    2: 'double11_purchases_merchant',\n",
    "    3: 'double11_favourites_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total actions by type for a given pair (user, merchant)\n",
    "to_merge = double11_users_merchants['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double11_clicks_user_merchant',\n",
    "    1: 'double11_carts_user_merchant',\n",
    "    2: 'double11_purchases_user_merchant',\n",
    "    3: 'double11_favourites_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double11 user features compared to total features\n",
    "df['double11_items_user_ratio'] = df['double11_items_user'] / (df['items_user'] + EPSILON)\n",
    "df['double11_categories_user_ratio'] = df['double11_categories_user'] / (df['categories_user'] + EPSILON)\n",
    "df['double11_merchants_user_ratio'] = df['double11_merchants_user'] / (df['merchants_user'] + EPSILON)\n",
    "df['double11_brands_user_ratio'] = df['double11_brands_user'] / (df['brands_user'] + EPSILON)\n",
    "df['double11_dates_user_ratio'] = df['double11_dates_user'] / (df['dates_user'] + EPSILON)\n",
    "df['double11_periods_user_ratio'] = df['double11_periods_user'] / (df['periods_user'] + EPSILON)\n",
    "df['double11_action_types_user_ratio'] = df['double11_action_types_user'] / (df['action_types_user'] + EPSILON)\n",
    "\n",
    "# double11 merchant features compared to total features\n",
    "df['double11_items_merchant_ratio'] = df['double11_items_merchant'] / (df['items_merchant'] + EPSILON)\n",
    "df['double11_categories_merchant_ratio'] = df['double11_categories_merchant'] / (df['categories_merchant'] + EPSILON)\n",
    "df['double11_users_merchant_ratio'] = df['double11_users_merchant'] / (df['users_merchant'] + EPSILON)\n",
    "df['double11_brands_merchant_ratio'] = df['double11_brands_merchant'] / (df['brands_merchant'] + EPSILON)\n",
    "df['double11_dates_merchant_ratio'] = df['double11_dates_merchant'] / (df['dates_merchant'] + EPSILON)\n",
    "df['double11_periods_merchant_ratio'] = df['double11_periods_merchant'] / (df['periods_merchant'] + EPSILON)\n",
    "df['double11_action_types_merchant_ratio'] = df['double11_action_types_merchant'] / (df['action_types_merchant'] + EPSILON)\n",
    "\n",
    "# double11 (user, merchant) features compared to total features\n",
    "df['double11_items_user_merchant_ratio'] = df['double11_items_user_merchant'] / (df['items_user_merchant'] + EPSILON)\n",
    "df['double11_categories_user_merchant_ratio'] = df['double11_categories_user_merchant'] / (df['categories_user_merchant'] + EPSILON)\n",
    "df['double11_brands_user_merchant_ratio'] = df['double11_brands_user_merchant'] / (df['brands_user_merchant'] + EPSILON)\n",
    "df['double11_dates_user_merchant_ratio'] = df['double11_dates_user_merchant'] / (df['dates_user_merchant'] + EPSILON)\n",
    "df['double11_periods_user_merchant_ratio'] = df['double11_periods_user_merchant'] / (df['periods_user_merchant'] + EPSILON)\n",
    "df['double11_action_types_user_merchant_ratio'] = df['double11_action_types_user_merchant'] / (df['action_types_user_merchant'] + EPSILON)\n",
    "\n",
    "# ratio of actions in each merchant (user perspective)\n",
    "df['double11_clicks_in_merchant_ratio_perspective'] = df['double11_clicks_user_merchant'] / (df['double11_clicks_user'] + EPSILON)\n",
    "df['double11_carts_in_merchant_ratio_perspective'] = df['double11_carts_user_merchant'] / (df['double11_carts_user'] + EPSILON)\n",
    "df['double11_purchases_in_merchant_ratio_perspective'] = df['double11_purchases_user_merchant'] / (df['double11_purchases_user'] + EPSILON)\n",
    "df['double11_favourites_in_merchant_ratio_perspective'] = df['double11_favourites_user_merchant'] / (df['double11_favourites_user'] + EPSILON)\n",
    "\n",
    "# ratio of actions in each merchant (merchant perspective)\n",
    "df['double11_clicks_by_user_ratio_perspective'] = df['double11_clicks_user_merchant'] / (df['double11_clicks_merchant'] + EPSILON)\n",
    "df['double11_carts_by_user_ratio_perspective'] = df['double11_carts_user_merchant'] / (df['double11_carts_merchant'] + EPSILON)\n",
    "df['double11_purchases_by_user_ratio_perspective'] = df['double11_purchases_user_merchant'] / (df['double11_purchases_merchant'] + EPSILON)\n",
    "df['double11_favourites_by_user_ratio_perspective'] = df['double11_favourites_user_merchant'] / (df['double11_favourites_merchant'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given user\n",
    "df['double11_clicks_user_ratio'] = df['double11_clicks_user'] / (df['double11_clicks_user'] + df['double11_carts_user'] + df['double11_purchases_user'] + df['double11_favourites_user'] + EPSILON)\n",
    "df['double11_carts_user_ratio'] = df['double11_carts_user'] / (df['double11_clicks_user'] + df['double11_carts_user'] + df['double11_purchases_user'] + df['double11_favourites_user'] + EPSILON)\n",
    "df['double11_purchases_user_ratio'] = df['double11_purchases_user'] / (df['double11_clicks_user'] + df['double11_carts_user'] + df['double11_purchases_user'] + df['double11_favourites_user'] + EPSILON)\n",
    "df['double11_favourites_user_ratio'] = df['double11_favourites_user'] / (df['double11_clicks_user'] + df['double11_carts_user'] + df['double11_purchases_user'] + df['double11_favourites_user'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given merchant\n",
    "df['double11_clicks_merchant_ratio'] = df['double11_clicks_merchant'] / (df['double11_clicks_merchant'] + df['double11_carts_merchant'] + df['double11_purchases_merchant'] + df['double11_favourites_merchant'] + EPSILON)\n",
    "df['double11_carts_merchant_ratio'] = df['double11_carts_merchant'] / (df['double11_clicks_merchant'] + df['double11_carts_merchant'] + df['double11_purchases_merchant'] + df['double11_favourites_merchant'] + EPSILON)\n",
    "df['double11_purchases_merchant_ratio'] = df['double11_purchases_merchant'] / (df['double11_clicks_merchant'] + df['double11_carts_merchant'] + df['double11_purchases_merchant'] + df['double11_favourites_merchant'] + EPSILON)\n",
    "df['double11_favourites_merchant_ratio'] = df['double11_favourites_merchant'] / (df['double11_clicks_merchant'] + df['double11_carts_merchant'] + df['double11_purchases_merchant'] + df['double11_favourites_merchant'] + EPSILON)\n",
    "\n",
    "# ratio of each action type for a given pair (user, merchant)\n",
    "df['double11_clicks_user_merchant_ratio'] = df['double11_clicks_user_merchant'] / (df['double11_clicks_user_merchant'] + df['double11_carts_user_merchant'] + df['double11_purchases_user_merchant'] + df['double11_favourites_user_merchant'] + EPSILON)\n",
    "df['double11_carts_user_merchant_ratio'] = df['double11_carts_user_merchant'] / (df['double11_clicks_user_merchant'] + df['double11_carts_user_merchant'] + df['double11_purchases_user_merchant'] + df['double11_favourites_user_merchant'] + EPSILON)\n",
    "df['double11_purchases_user_merchant_ratio'] = df['double11_purchases_user_merchant'] / (df['double11_clicks_user_merchant'] + df['double11_carts_user_merchant'] + df['double11_purchases_user_merchant'] + df['double11_favourites_user_merchant'] + EPSILON)\n",
    "df['double11_favourites_user_merchant_ratio'] = df['double11_favourites_user_merchant'] / (df['double11_clicks_user_merchant'] + df['double11_carts_user_merchant'] + df['double11_purchases_user_merchant'] + df['double11_favourites_user_merchant'] + EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Mean, Standard deviation and Median on user-merchant actions (grouping by users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmns = ['clicks_user_merchant', 'carts_user_merchant', 'purchases_user_merchant', 'favourites_user_merchant']\n",
    "\n",
    "to_merge = df.groupby('user_id')[clmns].max().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_user_merchant_max',\n",
    "    'carts_user_merchant': 'carts_user_merchant_max',\n",
    "    'purchases_user_merchant': 'purchases_user_merchant_max',\n",
    "    'favourites_user_merchant': 'favourites_user_merchant_max'\n",
    "})\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('user_id')[clmns].mean().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_user_merchant_mean',\n",
    "    'carts_user_merchant': 'carts_user_merchant_mean',\n",
    "    'purchases_user_merchant': 'purchases_user_merchant_mean',\n",
    "    'favourites_user_merchant': 'favourites_user_merchant_mean'\n",
    "})\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('user_id')[clmns].std().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_user_merchant_std',\n",
    "    'carts_user_merchant': 'carts_user_merchant_std',\n",
    "    'purchases_user_merchant': 'purchases_user_merchant_std',\n",
    "    'favourites_user_merchant': 'favourites_user_merchant_std'\n",
    "}).fillna(0)\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('user_id')[clmns].median().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_user_merchant_median',\n",
    "    'carts_user_merchant': 'carts_user_merchant_median',\n",
    "    'purchases_user_merchant': 'purchases_user_merchant_median',\n",
    "    'favourites_user_merchant': 'favourites_user_merchant_median'\n",
    "})\n",
    "df = df.merge(to_merge, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Mean, Standard deviation and Median on user-merchant actions (grouping by merchants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = df.groupby('merchant_id')[clmns].max().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_merchant_user_max',\n",
    "    'carts_user_merchant': 'carts_merchant_user_max',\n",
    "    'purchases_user_merchant': 'purchases_merchant_user_max',\n",
    "    'favourites_user_merchant': 'favourites_merchant_user_max'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('merchant_id')[clmns].mean().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_merchant_user_mean',\n",
    "    'carts_user_merchant': 'carts_merchant_user_mean',\n",
    "    'purchases_user_merchant': 'purchases_merchant_user_mean',\n",
    "    'favourites_user_merchant': 'favourites_merchant_user_mean'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('merchant_id')[clmns].std().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_merchant_user_std',\n",
    "    'carts_user_merchant': 'carts_merchant_user_std',\n",
    "    'purchases_user_merchant': 'purchases_merchant_user_std',\n",
    "    'favourites_user_merchant': 'favourites_merchant_user_std'\n",
    "}).fillna(0)\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = df.groupby('merchant_id')[clmns].median().rename(columns={\n",
    "    'clicks_user_merchant': 'clicks_merchant_user_median',\n",
    "    'carts_user_merchant': 'carts_merchant_user_median',\n",
    "    'purchases_user_merchant': 'purchases_merchant_user_median',\n",
    "    'favourites_user_merchant': 'favourites_merchant_user_median'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = df.drop(['kind', 'label'], axis=1)\n",
    "pca = PCA(n_components=PCA_COMPONENTS)\n",
    "pca.fit(pca_df)\n",
    "df = df.join(pd.DataFrame(pca.transform(pca_df), index=pca_df.index).add_prefix('pca_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing Touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['kind'] == 'train'].drop(['kind'], axis=1)\n",
    "df_test = df[df['kind'] == 'test'].drop(['kind', 'label'], axis=1)\n",
    "X, y = df_train.drop(columns='label'), df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch best features\n",
    "The xgboost object will train the model with all features, then the booster object (returned after training) can calculate which features best contribute for most information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=VALID_SET_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "dtrain = DMatrix(X_train, label=y_train)\n",
    "dvalid = DMatrix(X_valid, label=y_valid)\n",
    "watchlist = [(dvalid, 'valid')]\n",
    "params = {\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 200, \n",
    "    'colsample_bytree': 0.8, \n",
    "    'subsample': 0.8, \n",
    "    'eta': 0.04,    \n",
    "    'seed': RANDOM_SEED,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "booster = train(params, dtrain, num_boost_round=2000, evals=watchlist, early_stopping_rounds=50, verbose_eval=True)\n",
    "best_features = pd.DataFrame(booster.get_score(importance_type='gain').items(), columns=['features', 'importance'])\n",
    "best_features = best_features.sort_values(by=['importance'], ascending=False)['features'].to_numpy()[: N_FEATURES]\n",
    "X = X[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'CatBoostClassifier': [CatBoostClassifier, {\n",
    "        'depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': 1200,\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'thread_count': 8,\n",
    "        'silent': True\n",
    "    }],\n",
    "    'LGBMClassifier': [LGBMClassifier, {\n",
    "        'n_estimators': 2000,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 50,\n",
    "        'learning_rate': 0.03,\n",
    "        'reg_lambda': 1,\n",
    "        'objective': 'binary',\n",
    "        'metric': ['auc'],\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'n_jobs': -1\n",
    "    }],\n",
    "    'XGBClassifier': [XGBClassifier, {\n",
    "        'max_depth': 7,\n",
    "        'n_estimators': 1000,\n",
    "        'min_child_weight': 200,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'eta': 0.04,\n",
    "        'objective': 'binary:logistic',\n",
    "        'use_label_encoder': False,\n",
    "        'seed': RANDOM_SEED\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training + Cross Validation (10Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}\n",
    "X, y = X.to_numpy(), y.to_numpy() \n",
    "\n",
    "for name, model_params in models.items():\n",
    "\n",
    "    _class, params = model_params\n",
    "    model_records = {'best_score': 0, 'scores': []}\n",
    "\n",
    "    kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "    \n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "        model = _class(**params)\n",
    "\n",
    "        fit_params = {\n",
    "            'CatBoostClassifier': {},\n",
    "            'LGBMClassifier': {},\n",
    "            'XGBClassifier': {\n",
    "                'eval_metric': 'auc',\n",
    "                'eval_set': [(X_train, y_train), (X_valid, y_valid)],\n",
    "                'early_stopping_rounds': 50,\n",
    "                'verbose': False\n",
    "            }\n",
    "        }\n",
    "\n",
    "        model.fit(X_train, y_train, **fit_params[name])\n",
    "        predictions = model.predict_proba(X_valid)[:,1]\n",
    "        model_records['scores'].append(roc_auc_score(y_valid, predictions))\n",
    "        if model_records['scores'][-1] > model_records['best_score']:\n",
    "            model_records['best_score'] = model_records['scores'][-1]\n",
    "            model_records['best_instance'] = model\n",
    "\n",
    "    records[name] = model_records\n",
    "\n",
    "    print(f'% {name} %')\n",
    "    print('mean score: {0:.4f}'.format(np.mean(model_records['scores'])))\n",
    "    print('best score: {0:.4f}'.format(model_records['best_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predictions from Best Model Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'CatBoostClassifier': 0.20,\n",
    "    'LGBMClassifier': 0.10,\n",
    "    'XGBClassifier': 0.70\n",
    "}\n",
    "\n",
    "prob_submission = np.zeros(df_test.shape[0])\n",
    "for name, weight in weights.items():\n",
    "    prob_submission += records[name]['best_instance'].predict_proba(df_test[best_features].to_numpy())[:, 1]*weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.iloc[:,:2].join(pd.DataFrame(prob_submission, index=df_test.index).rename(columns={0:'prob'}))\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52143a4c1d3c54e78ec3a6dc4e56afb88afff4ca0e9824f0ff9251ac34bb2b12"
  },
  "kernelspec": {
   "display_name": "PyCharm (Project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
